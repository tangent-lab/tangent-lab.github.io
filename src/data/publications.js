export const publications = [
  {
    title:
      "DiminishAR: Diminishing Visual Distractions via Holographic AR Displays",
    abstract:"Full details to be released.",
    authors: "JangHyeon Lee, Lawrence Kim",
    institutions: "Simon Fraser University",
    venue: "CHI 2025",
    year: 2025,
    tags: ["accepted"],
    image:"/assets/images/publications/DiminishAR.gif",
    links: [
    ],
  },
  {
    title:
      "Co-Design and Evaluation of Visual Interventions for Head Posture Correction in Virtual Reality Games",
    abstract:"Full details to be released.",
    authors: "Minh Duc Dang, Duy Phuoc Luong, Christopher Napier, Lawrence Kim",
    institutions: "Simon Fraser University",
    venue: "CHI 2025",
    year: 2025,
    tags: ["accepted"],
    image:"/assets/images/publications/VR Posture.png",
    links: [
    ],
  },
  {
    title:
      "User-Defined Co-Speech Gesture Design with Swarm Robots",
    abstract:"Full details to be released.",
    authors: "Minh Duc Dang, Samira Pulatova, Lawrence Kim",
    institutions: "Simon Fraser University",
    venue: "CHI 2025",
    year: 2025,
    tags: ["accepted"],
    image:"/assets/images/publications/SwarmCoSpeechGesture.gif",
    links: [
    ],
  },

  {
    title:
      "Co-Designing Programmable Fidgeting Experience with Swarm Robots for Adults with ADHD",
    abstract:
      "Individuals with ADHD grapple with elevated stress levels, emotional regulation challenges, and difficulty sustaining focus. Fidgeting, a behavior traditionally frowned upon, has been shown to help people with ADHD in concentration, emotional and mental state management, and energy regulation. However, traditional fidgeting devices have limited fixed affordances providing cookie-cutter style fidgeting experience to all despite individual differences. Recognizing the uniqueness of individual fidgeting tendencies, we use small tabletop robots to provide a customizable fidgeting interaction experience and conduct co-design sessions with 16 adults diagnosed with ADHD to explore how they envision their fidgeting interactions being changed with these programmable robots. We examine core elements defining a successful fidgeting interaction with robots, assess the significance of customizability in these interactions and any common trends among participants, and investigate additional advantages that interactions with robots may offer. This research reveals nuanced preferences of adults with ADHD concerning robot-assisted fidgeting.",
    authors: "Samira Pulatova, Lawrence Kim",
    institutions: "Simon Fraser University",
    venue: "ASSETS 2024",
    year: 2024,
    tags: [],
    image: "/assets/images/publications/codesign.gif",
    links: [
      {
        title: "Presentation",
        url: "https://www.youtube.com/watch?v=vglfyKbNiHE&ab_channel=SFUTangentLab",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2024-SwarmFidgetADHD/ASSETS%20preprint.pdf",
      },
    ],
  },
  
  {
    title:
      "React to This! How Humans Challenge Interactive Agents using Nonverbal Behaviors",
    abstract:
      "How do people use their faces and bodies to test the interactive abilities of a robot? Making lively, believable agents is often seen as a goal for robots and virtual agents but believability can easily break down. In this Wizard-of-Oz (WoZ) study, we observed 1169 nonverbal interactions between 20 participants and 6 types of agents. We collected the nonverbal behaviors participants used to challenge the characters physically, emotionally, and socially. The participants interacted freely with humanoid and non-humanoid forms: arobot, a human, a penguin, a pufferfish, a banana, and a toilet. We present a human behavior codebook of 188 unique nonverbal behaviors used by humans to test the virtual characters. The insights and design strategies drawn from video observations and participant interviews aim to help build more interaction- aware and believable robots and agents in the future",
    authors: "Chuxuan Zhang, Bermet Burkanova, Lawrence Kim, Lauren Yip, Ugo Cupcic, Stéphane Lallée, Angelica Lim",
    institutions: "Simon Fraser University, Spoon AI",
    venue: "IROS 2024",
    year: 2024,
    tags: [],
    image: "/assets/images/publications/IROS.gif",
    links: [
      {
        title: "Presentation",
        url: "https://www.youtube.com/watch?v=QRi5o5v_leY&ab_channel=SFURosieLab",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2024-ReactToThis/IROS-preprint.pdf",
      },
    ],
  },
  
  {
    title:
      "Impact of Multi-Robot Presence and Anthropomorphism on Human Cognition and Emotion",
    abstract:
      "Exploring how robots impact human cognition and emotions has become increasingly important as robots gradually become ubiquitous in our lives. In this study, we investigate the impact of robotic presence on human cognition and emotion by examining various robot parameters such as anthropomorphism, number of robots, and multi-robot motion patterns. 16 participants completed two cognitive tasks in the presence of anthropomorphic and nonanthropomorphic robots, alone, and with a human nearby. The non-anthropomorphic robot conditions were further varied in the number of robots and their motion patterns. We find that increasing the number of non-anthropomorphic robots generally leads to slower performance, but coordinated patterned motions can lower the completion time compared to random movements. An anthropomorphic robot induces an increased level of feelings of being judged compared to a non-anthropomorphic robot. These findings provide preliminary insights into how designers or users can purposefully integrate robots into our environment by understanding the effects of anthropomorphism, number of robots, and multi-robot motion patterns on human cognition and emotion.",
    authors: "Jiadi Luo, Veronika Domova, Lawrence Kim",
    institutions: "Simon Fraser University",
    venue: "CHI 2024",
    year: 2024,
    tags: [],
    image: "/assets/images/publications/multi-robot.gif",
    links: [
      {
        title: "Video",
        url: "https://www.youtube.com/watch?v=_plPdD05mSQ",
      },
      {
        title: "Presentation",
        url: "https://www.youtube.com/watch?v=yAA-sZ6ViqI&ab_channel=ACMSIGCHI",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2024-MultiRobotPresence/MultiRobotPresence-Preprint.pdf",
      },
    ],
  },

  {
    title:
      "SwarmFidget: Exploring Programmable Actuated Fidgeting with Swarm Robots",
    abstract:
      "We introduce the concept of programmable actuated fdgeting, a type of fdgeting that involves devices integrated with actuators, sensors, and computing to enable a customizable interactive fdgeting experience. In particular, we explore the potential of a swarm of tabletop robots as an instance of programmable actuated fdgeting as robots are becoming increasingly available. Through ideation sessions among researchers and feedback from the participants, we formulate the design space for SwarmFidget, where swarm robots are used to facilitate programmable actuated fdgeting. To gather user impressions, we conducted an exploratory study where we introduced the concept of SwarmFidget to twelve participants and had them experience and provide feedback on six example fdgeting interactions. Our study demonstrates the potential of SwarmFidget for facilitating fdgeting interaction and provides insights and guidelines for designing efective and engaging fdgeting interactions with swarm robots. We believe our work can inspire future research in the area of programmable actuated fdgeting and open up new opportunities for designing novel swarm robot-based fdgeting systems.",
    authors: "Lawrence Kim, Veronika Domova, Yuqi Yao, Parsa Rajabi",
    institutions: "Simon Fraser University",
    venue: "UIST 2023",
    year: 2023,
    tags: [],
    image: "/assets/images/publications/swarmfidget.gif",
    links: [
      {
        title: "Video",
        url: "https://www.youtube.com/watch?v=gy4rGCqOujs&ab_channel=SFUTangentLab",
      },
      {
        title: "Presentation",
        url: "https://www.youtube.com/live/IiKX6HRSiSk?si=Rc6QybQlDvnZSwjq&t=13682",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2023-SwarmFidget/SwarmFidget.pdf",
      },
    ],
  },

  {
    title:
      "Shared Autonomy to Reduce Sedentary Behavior Among Sit-Stand Desk Users in the United States and India: Web-Based Study",
      abstract: `
      Background:
      Fitness technologies such as wearables and sit-stand desks are increasingly being used to fight sedentary lifestyles by encouraging physical activity. However, adherence to such technologies decreases over time because of apathy and increased dismissal of behavioral nudges.
      
      Objective:
      To address this problem, we introduced shared autonomy in the context of sit-stand desks, where user input is integrated with robot autonomy to control the desk and reduce sedentary behavior and investigated user reactions and preferences for levels of automation with a sit-stand desk. As demographics affect user acceptance of robotic technology, we also studied how perceptions of nonvolitional behavior change differ across cultures (United States and India), sex, familiarity, dispositional factors, and health priming messages.
      
      Methods:
      We conducted a web-based vignette study in the United States and India where a total of 279 participants watched video vignettes of a person interacting with sit-stand desks of various levels of automation and answered questions about their perceptions of the desks such as ranking of the different levels of automation.
      
      Results:
      Participants generally preferred either manual or semiautonomous desks over the fully autonomous option. However, participants in India were generally more amenable to the idea of nonvolitional interventions from the desk than participants in the United States. Male participants had a stronger desire for having control over the desk than female participants (P=.01). Participants who were more familiar with sit-stand desks were more likely to adopt autonomous sit-stand desks (P=.001). No effects of health priming messages were observed. We estimated the projected health outcome by combining ranking data and hazard ratios from previous work and found that the semiautonomous desk led to the highest projected health outcome.
      
      Conclusions:
      These results suggest that the shared autonomy desk is the optimal level of automation in terms of both user preferences and estimated projected health outcomes. Demographics such as culture and sex had significant effects on how receptive users were to autonomous intervention. As familiarity improves the likelihood of adoption, we propose a gradual behavior change intervention to increase acceptance and adherence, especially for populations with a high desire for control.
      `,
    authors: "Lawrence Kim, Gourab Saha, Annel Amelia Leon, Abby C. King, Matthew L. Mauriello, Pablo E. Paredes",
    institutions: "Simon Fraser University, Stanford University, University of Delaware, University of Maryland",
    venue: "JMIR Formative Research 2022",
    year: 2022,
    type: '',
    tags: [],
    image: "/assets/images/publications/StandingDesk-ToC.png",
    links: [
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2022-SharedAutonomy/SharedAutonomy.pdf",
      },
    ],
  },

  {
    title:
      "Effects of a Co-Located Robot and Anthropomorphism on Human Motivation and Emotion across Personality and Gender",
    abstract:
      "In this paper, we study how a co-located robot affects human motivation and emotion. In particular, we examine the role of the co-located robot’s anthropomorphism, as well as the effects of the human’s personality and gender. To study this, we conducted an online experiment, where 182 participants completed a repetitive task, either easy or hard, in one of the four conditions: in the presence of a nonanthropomorphic robot, an anthropomorphic robot, another human, or alone. For each condition, we analyzed the number of repetitions and the total time users spent, which we treated as the proxy of their motivation, as well as their self-reported emotional states. The study results suggest that the presence of a non-anthropomorphic robot has the potential to lead to a higher level of motivation and a more desirable affective state for users than the presence of an anthropomorphic robot or another human, especially for introverts and female users during difficult tasks.",
    authors: "Lawrence Kim, Veronika Domova, Yuqi Yao, Pablo E. Paredes",
    institutions: "",
    venue: "RO-MAN 2022",
    year: 2022,
    tags: [],
    image: "/assets/images/publications/ROMAN.gif",
    links: [
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2022-RoboticPresence/ROMAN-Preprint.pdf",
      },
    ],
  },
  {
    title:
      "Robotic Presence: The Effects of Anthropomorphism and Robot State on Task Performance and Emotion",
    abstract:
      "Robots are becoming more ubiquitous in our daily lives including in our offices and homes. As such, it is necessary to understand whether and how robotic presence affects us both emotionally and cognitively. In this work, we investigate the effects of anthropomorphism and robot state of robotic presence on task performance and user emotion. In an online study, 113 participants completed three tasks within a virtual 3D environment in the presence of robots with varying anthropomorphism (non-anthropomorphic vs. anthropomorphic) and robot state (active vs. idle) in addition to alone and with a human. The study findings suggest that having an active moving robot can expedite the task performance especially for easy difficulty levels albeit with some decrease in accuracy, while anthropomorphism affects the dominance axis of affect and has interaction effects with the robot state. The robot state also had as much influence on the perceived anthropomorphism and animacy as the anthropomorphism of the robot. These results provide initial insights on the effects of robotic presence and the impact of the robot state and anthropomorphism.",
    authors: "Lawrence Kim, Veronika Domova, Yuqi Yao, Chien-Ming Huang, Sean Follmer, Pablo E. Paredes",
    institutions: "",
    venue: "RA-L 2022",
    year: 2022,
    tags: [],
    image: "/assets/images/publications/RoboticPresence.gif",
    links: [
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2022-RoboticPresence/RAL-Preprint.pdf",
      },
    ],
  },
  {
    title:
      "Linear Predictive Coding for Acute Stress Prediction from Computer Mouse Movements",
    abstract:
      "Prior work demonstrated the potential of using the Linear Predictive Coding (LPC) filter to approximate muscle stiffness and damping from computer mouse movements to predict acute stress levels of users. Theoretically, muscle stiffness and damping in the arm can be estimated using a mass-spring-damper (MSD) biomechanical model. However, the damping frequency (i.e., stiffness) and damping ratio values derived using LPC were not yet compared with those from a theoretical MSD model. This work demonstrates that the damping frequency and damping ratio from LPC are significantly correlated with those from an MSD model, thus confirming the validity of using LPC to infer muscle stiffness and damping. We also compare the stress level binary classification performance using the values from LPC and MSD with each other and with neural network-based baselines. We found comparable performance across all conditions demonstrating LPC and MSD model-based stress prediction efficacy, especially for longer mouse trajectories.",
    authors: "Lawrence Kim, Rahul Goel, Jia Liang, Mert Pilanci, Pablo E. Paredes",
    institutions: "",
    venue: "EMBC 2021",
    year: 2021,
    tags: [],
    image: "/assets/images/publications/mousemoving.gif",
    links: [
      {
        title:"Slides",
        url:"https://www.lhkim.com/Projects/2021-LPC/EMBC'21%20Presentation%20Slides.pdf",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2021-LPC/20210730-LPC___EMBC__21.pdf",
      },
    ],
  },

  {
    title:
      "Generating Legible and Glanceable Swarm Robot Motion Through Trajectory, Collective Behavior, and Pre-Attentive Processing Features",
    abstract:
      "As swarm robots begin to share the same space with people, it is critical to design legible swarm robot motion that clearly and rapidly communicates the intent of the robots to nearby users. To address this, we apply concepts from intent-expressive robotics, swarm intelligence, and vision science. Specifically, we leverage the trajectory, collective behavior, and density of swarm robots to generate motion that implicitly guides people’s attention toward the goal of the robots. Through online evaluations, we compared different types of intent-expressive motions both in terms of legibility as well as glanceability, a measure we introduce to gauge an observer’s ability to predict robots’ intent pre-attentively. The results show that the collective behavior- based motion has the best legibility performance overall, whereas, for glanceability, trajectory-based legible motion is most effective. These results suggest that the optimal solution may involve a combination of these legibility cues based on the scenario and the desired properties of the motion.",
    authors: "Lawrence Kim, Sean Follmer",
    institutions: "",
    venue: "THRI 2021",
    year: 2021,
    type: '',
    tags: [],
    image: "/assets/images/publications/SwarmLegibility.gif",
    links: [
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2021-SwarmLegibility/20210710-T_HRI_Legibility_NOCOPYRIGHT.pdf",
      },
    ],
  },
  
  {
    title:
      "The Haunted Desk: Exploring Non-Volitional Behavior Change with Everyday Robotics",
    abstract:
      "We introduce and explore the concept of non-volitional behavior change, a novel category of behavior change interventions, and apply it in the context of promoting healthy behaviors through an automated sit-stand desk. While routine use of sit-stand desks can increase health outcomes, compliance decreases quickly and behavioral nudges tend to be dismissed. To address this issue, we introduce robotic furniture that moves on its own to promote healthy movement. In an in-person preliminary study, we explored users’ impressions of an autonomous sit-stand desk prototype that changes position at regular pre-set time intervals while participants complete multiple tasks. While in-the-moment self-reported ratings were similar between the autonomous and manual desks, we observed several bi-modal distributions in user’s retrospective comparisons and their qualitative responses. Findings suggest about half were receptive to using an autonomous sit-stand desk, while the remaining preferred to retain some level of control.",
    authors: "Lawrence Kim, Annel Amelia Leon, Ganapathy Sankararaman, Blake M. Jones, Gourab Saha, Amanda Spyropolous, Akshara Motani, Matthew L. Mauriello, Pablo E. Paredes",
    institutions: "",
    venue: "HRI 2021 Companion",
    year: 2021,
    award: "Best LBR Award Nominee",
    tags: ["mention"],
    image: "/assets/images/publications/Haunted_Desk.gif",
    links: [
      {
        title:"Slides",
        url:"https://docs.google.com/presentation/d/1MpP8JUB8Zoo7_WzlsTamBju4ptW-3dZFcVa63SsC0g8/edit?usp=sharing",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2021-HauntedDesk/Haunted_Desk_HRI_LBR-no_copyright.pdf",
      },
    ],
  },

  {
    title:
      "Automatic Generation of Spatial Tactile Effects by Analyzing Cross-modality Features of a Video",
    abstract:
      "Tactile effects can enhance user experience of multimedia content. However, generating appropriate tactile stimuli without any human intervention remains a challenge. While visual or audio information has been used to automatically generate tactile effects, utilizing cross-modal information may further improve the spatiotemporal synchronization and user’s experience of the tactile effects. In this paper, we present a pipeline for automatic generation of vibrotactile effects through the extraction of both the visual and audio features from a video. Two neural network models are used to extract the diegetic audio content and localize a sounding object in the scene. These models are then used to determine the spatial distribution and the intensity of the tactile effects. To evaluate the performance of our method, we conducted a user study to compare the videos with tactile effects generated by our method to both the original videos without any tactile stimuli and videos with tactile effects generated based on visual features only. The study results demonstrate that our cross-modal method creates tactile effects with better spatiotemporal synchronization than the existing visual-based method and provides a more immersive user experience.",
    authors: "Kai Zhang, Lawrence Kim, Yipeng Guo, Sean Follmer",
    institutions: "",
    venue: "SUI 2020",
    year: 2020,
    type: '',
    tags: [],
    image: "/assets/images/publications/SUI-dog.gif",
    links: [
      {
        title:"Video",
        url:"https://www.youtube.com/watch?v=sq7Xs_tDYCA&feature=emb_logo&ab_channel=ACMSUI2020Conference",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2020-Cross-modality/Kai-SUI.pdf",
      },
    ],
  },

  {
    title:
      "When to Add Human Narration to Photo-Sharing Social Media",
    abstract: "",
    authors: "Lawrence Kim, Abena Boadi-Agyemang*, Alexa F. Siu, John Tang",
    institutions: "",
    venue: "ASSETS 2020 Poster",
    year: 2020,
    type: '',
    tags: [],
    image: "/assets/images/publications/SocialMedia.jpg",
    links: [
      {
        title:"Video",
        url:"https://youtu.be/-U74enU5xo8",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/Posters/ASSETS'20.pdf",
      },
    ],
  },

  {
    title:
      "User-defined Swarm Robot Control",
    abstract: 
      "A swarm of robots can accomplish more than the sum of its parts, and swarm systems will soon see increased use in applications ranging from tangible interfaces to search and rescue teams. However, effective human control of robot swarms has been shown to be demonstrably more diffcult than controlling a single robot, and swarm-specifc interactions methodologies are relatively underexplored. As we envision even non-expert users will have more daily in-person encounters with different numbers of robots in the future, we present a user-defned set of control interactions for tabletop swarm robots derived from an elicitation study. We investigated the effects of number of robots and proximity on the user’s interaction and found signifcant effects. For instance, participants varied between using 1-2 fngers, one hand, and both hands depending on the group size. We also provide general design guidelines such as preferred interaction modality, common strategies, and a high-agreement interaction set.",
    authors: "Lawrence Kim, Daniel Drew, Veronika Domova, Sean Follmer",
    institutions: "",
    venue: "CHI 2020",
    year: 2020,
    award: 'Best Paper Honorable Mention',
    tags: ["mention"],
    image: "/assets/images/publications/control.gif",
    links: [
      {
        title:"Video",
        url:"https://youtu.be/RfzAkW34J78",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2020-Control/SwarmControl.pdf",
      },
    ],
  },

  {
    title:
      "VPS Display: Tactile Information Transfer through Vibration, Pressure, and Shear",
    abstract: 
      "One of the challenges in the field of haptics is to provide meaningful and realistic sensations to users. While most real world tactile sensations are composed of multiple dimensions, most commercial product only include vibration as it is the most cost effective solution. To improve on this, we introduce VPS (Vibration, Pressure, Shear) display, a multi-dimensional tactile array that increases information transfer by combining Vibration, Pressure, and Shear similar to how RGB LED combines red, blue, and green to create new colors. We characterize the device performance and dynamics for each tactile dimension in terms of its force and displacement profiles, and evaluate information transfer of the VPS display through a stimulus identification task. Our results indicate that the information transfer through a single taxel increases from 0.56 bits to 2.15 bits when pressure and shear are added to vibrations with a slight decrease in identification accuracy. We also explored the pleasantness and continuity of VPS and the study results reveal that tactile strokes in shear mode alone are rated highest on perceived pleasantness and continuity.",
    authors: "Lawrence Kim, Pablo Castillo, Sean Follmer, Ali Israr",
    institutions: "",
    venue: "IMWUT 2019",
    year: 2019,
    type: '',
    tags: [],
    image: "/assets/images/publications/VPS.gif",
    links: [
      {
        title:"Video",
        url:"https://www.youtube.com/watch?v=QV9gcO9yIYc",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2019-VPS/VPS-preprint.pdf",
      },
    ],
  },

  {
    title:
      "SwarmHaptics: Haptic Display with Swarm Robots",
    abstract: 
      "We introduce SwarmHaptics, a new type of haptic display using a swarm of small, wheeled robots. These robots move on a flat surface and apply haptic patterns to the user's hand, arm, or any other accessible body parts. We explore the design space of SwarmHaptics including individual and collective robot parameters, and demonstrate example scenarios including remote social touch using the Zooids platform. To gain insights into human perception, we applied haptic patterns with varying number of robots, force type, frequency, and amplitude and obtained user's perception in terms of emotion, urgency, and Human-Robot Interaction metrics. In a separate elicitation study, users generated a set of haptic patterns for social touch. The results from the two studies help inform how users perceive and generate haptic patterns with SwarmHaptics.",
    authors: "Lawrence Kim, Sean Follmer",
    institutions: "",
    venue: "CHI 2019",
    year: 2019,
    award: 'Best Paper Honorable Mention',
    tags: ["mention"],
    image: "/assets/images/publications/haptics.gif",
    links: [
      {
        title:"Video",
        url:"https://www.youtube.com/watch?v=D-GcfZZV96M",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2019-SwarmHaptics/SwarmHaptics.pdf",
      },
    ],
  },

  {
    title:
      "Robotic Assembly of Haptic Proxy Objects for Tangible Interaction and Virtual Reality",
    abstract: 
      "Passive haptic proxy objects allow for rich tangible interaction, and this is especially true in VR applications. However, this requires users to have many physical objects at hand. Our paper proposes robotic assembly at run-time of low-resolution haptic proxies for tangible interaction and virtual reality. These assembled physical proxy objects are composed of magnetically attached blocks which are assembled by a small multi robot system, specifically Zooids. We explore the design of the basic building blocks and illustrate two approaches to assembling physical proxies: using multirobot systems to (1) self-assemble into structures and (2) assemble 2.5D structure with passive blocks of various heights. The success rate and completion time are evaluated for both approaches. Finally, we demonstrate the potential of assembled proxy objects for tangible interaction and virtual reality through a set of demonstration.",
    authors: "Yiwei Zhao, Lawrence Kim, Mathieu Le Goc, Sean Follmer",
    institutions: "",
    venue: "ISS 2017",
    year: 2017,
    type: '',
    tags: [],
    image: "/assets/images/publications/assembly.gif",
    links: [
      {
        title:"Video",
        url:"https://www.youtube.com/watch?v=-Jewb-Mrzz0",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2017-roboticAssembly/roboticAssembly_ISS_2017.pdf",
      },
    ],
  },

  {
    title:
      "UbiSwarm: Ubiquitous Robotic Interfaces and Investigation of Abstract Motion as a Display",
    abstract: 
      "As robots increasingly enter our everyday life, we envision a future in which robots are ubiquitous and interact with both ourselves and our environments. This paper introduces the concept ofubiquitous robotic interfaces (URIs), multi-robot interfaces capable of mobility, manipulation, sensing, display and interaction. URIs interact directly with the user and indirectly through surrounding objects. A key aspect of URIs is their ability to display information to users either by collectively forming shapes or through their movements. In this paper, we focus on the use of URIs to display information in ubiquitous settings. We first investigate the use of abstract motion as a display for URIs by studying human perception of abstract multi-robot motion. With ten small robots, we produced 42 videos of bio-inspired abstract motion by varying three parameters (7 x 2 x 3): bio-inspired behavior, speed and smoothness. In a crowdsourced between-subjects study, 1067 subjects were recruited to watch the videos and describe their perception through Likert scales and free text. Study results suggest that different bio-inspired behaviors elicit significantly different responses in arousal, dominance, hedonic and pragmatic qualities, animacy, urgency and willingness to attend. On the other hand, speed significantly affects valence, arousal, hedonic quality, urgency and animacy while smoothness affects hedonic quality, animacy, attractivity and likeability. We discuss how these results inform URI designers to formulate appropriate motion for different interaction scenarios and use these results to derive our own example applications using our URI platform, UbiSwarm.",
    authors: "Lawrence Kim, Sean Follmer",
    institutions: "",
    venue: "IMWUT 2017",
    year: 2017,
    type: '',
    tags: [],
    image: "/assets/images/publications/ubiswarm.gif",
    links: [
      {
        title:"Video",
        url:"https://www.youtube.com/watch?v=oT7theBRBzI",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2017-UbiSwarm/UbiSwarm_Nocopyright.pdf",
      },
    ],
  },

  {
    title:
      "Human Perception of Swarm Robot Motion",
    abstract: "",
    authors: "Griffin Dietz, Jane L. E, Peter Washington, Lawrence Kim, Sean Follmer",
    institutions: "",
    venue: "CHI 2017 Extended Abstract",
    year: 2017,
    type: '',
    tags: [],
    image: "/assets/images/publications/SwarmMotionPerception.gif",
    links: [
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/Posters/Perception_nocopyright.pdf",
      },
    ],
  },


  {
    title:
      "Zooids: Building Blocks for Swarm User Interfaces",
    abstract: 
      "This paper introduces swarm user interfaces, a new class of human-computer interfaces comprised of many autonomous robots that handle both display and interaction. We describe the design of Zooids, an open-source open-hardware platform for developing tabletop swarm interfaces. The platform consists of a collection of custom-designed wheeled micro robots each 2.6 cm in diameter, a radio base-station, a high-speed DLP structured light projector for optical tracking, and a software framework for application development and control. We illustrate the potential of tabletop swarm user interfaces through a set of application scenarios developed with Zooids, and discuss general design considerations unique to swarm user interfaces.",
    authors: "Mathieu Le Goc, Lawrence Kim, Ali Parsaei,Jean-Daniel Fekete, Pierre Dragicevic, Sean Follmer",
    institutions: "",
    venue: "UIST 2016",
    year: 2016,
    award: 'Best Paper Award',
    tags: ["best"],
    image: "/assets/images/publications/Zooids.gif",
    links: [
      {
        title:"Video",
        url:"https://www.youtube.com/watch?v=ahHjSY_GLDg",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2016-Zooids/SwarmUIs_no_copyright.pdf",
      },
    ],
  },

  {
    title:
      "Haptic Edge Display for Mobile Tactile Interaction",
    abstract: 
      "Current mobile devices do not leverage the rich haptic channel of information that our hands can sense, and instead focus primarily on touch based graphical interfaces. Our goal is to enrich the user experience of these devices through bidirectional haptic and tactile interactions (display and control) around the edge of hand-held devices. We propose a novel type of haptic interface, a Haptic Edge Display, consisting of actuated pins on the side of a display, to form a linear array of tactile pixels (taxels). These taxels are implemented using small piezoelectric actuators, which can be made cheaply and have ideal characteristics for mobile devices. We developed two prototype Haptic Edge Displays, one with 24 actuated pins (3.75mm in pitch) and a second with 40 pins (2.5mm in pitch). This paper describes several novel haptic interactions for the Haptic Edge Display including dynamic physical affordances, shape display, non-dominant hand interactions, and also in-pocket \"pull\"style haptic notifications. In a laboratory experiment we investigated the limits of human perception for Haptic Edge Displays, measuring the just-noticeable difference for pin width and height changes for both in-hand and simulated in-pocket conditions.",
    authors: "Sungjune Jang, Lawrence Kim, Kesler Tanner, Hiroshi Ishii, Sean Follmer",
    institutions: "",
    venue: "CHI 2016",
    year: 2016,
    type: '',
    tags: [],
    image: "/assets/images/publications/hedge.gif",
    links: [
      {
        title:"Video",
        url:"https://www.youtube.com/watch?v=LKHYFLRiF28",
      },
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2016-hapticEdgeDisplay/Haptic_Edge_Display_no_copyright.pdf",
      },
    ],
  },

  {
    title:
      "Design and evaluation of a trilateral shared-control architecture for teleoperated training robots",
    abstract: 
      "Multilateral teleoperated robots can be used to train humans to perform complex tasks that require collaborative interaction and expert supervision, such as laparoscopic surgical procedures. In this paper, we explain the design and performance evaluation of a shared-control architecture that can be used in trilateral teleoperated training robots. The architecture includes dominance and observation factors inspired by the determinants of motor learning in humans, including observational practice, focus of attention, feedback and augmented feedback, and self- controlled practice. Toward the validation of such an architecture, we (1) verify the stability of a trilateral system by applying Llewellyn’s criterion on a two-port equivalent architecture, and (2) demonstrate that system transparency remains generally invariant across relevant observation factors and movement frequencies. In a preliminary experimental study, a dyad of two human users (one novice, one expert) collaborated on the control of a robot to follow a trajectory. The experiment showed that the framework can be used to modulate the efforts of the users and adjust the source and level of haptic feedback to the novice.",
    authors: "Kamran Shamaei, Lawrence Kim, Allison M. Okamura",
    institutions: "",
    venue: "EMBC 2015",
    year: 2015,
    type: '',
    tags: [],
    image: "/assets/images/publications/shared.jpg",
    links: [
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2015-Trilateral/Trilateral_Architecture_IEEE.pdf",
      },
    ],
  },

  {
    title:
      "Effects of Master-Slave Tool Misalignment in a Teleoperated Surgical Robot",
    abstract: 
      "In a teleoperated system, misalignment between the master and slave manipulators can result from clutching, errors in the kinematic model, and/or sensor errors. This study examines the effects of type and magnitude of misalignment on the performance of the teleoperator. We first characterized the magnitude and direction of orientation misalignment created when clutching and unclutching during use of two surgical robots: the Raven II and the da Vinci Research Kit. We then purposely generated typical misalignments in order to measure the impact of such misalignment on user performance of a peg transfer task with the Raven II. Users were able to compensate for misalignment angles up to approximately 20 degrees in both tool orientation and camera viewpoint misalignment. These results can be used to guide the design and control of teleoperated systems for a variety of applications.",
    authors: "Lawrence Kim*, Clifford Bargar*, Yuhang Che*, Allison M. Okamura",
    institutions: "",
    venue: "ICRA 2015",
    year: 2015,
    type: '',
    tags: [],
    image: "/assets/images/publications/diffaxis - high.jpg",
    links: [
      {
        title: "PDF",
        url: "https://www.lhkim.com/Projects/2015-misalignment/ToolMisalignment_Revised_2_26.pdf",
      },
    ],
  },

]