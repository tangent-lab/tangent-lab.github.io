export const news = [
  /*
  {
    title: "Seeking Prospective Students",
    date: "Jan, 2025",
    description: "We are actively looking for exceptional students at the intersection of Human Computer Interaction, Electrical Engineering, Materials Science and Mechanical Engineering. If you are interested in working with us, please email me with your CV and transcript to Prof. Lawrence Kim.",
    url: "https://www.lhkim.com/",
    image:"/assets/images/publications/Zooids.gif",
    tag:"Position",
    article:"We are actively looking for exceptional students at the intersection of Human Computer Interaction, Electrical Engineering, Materials Science and Mechanical Engineering. If you are interested in working with us, please email me with your CV and transcript to Prof. Lawrence Kim.",
  },
  */
  {
    title: "Xueying Awarded GROWW Scholarship",
    date: "May, 2025",
    description: "We are proud to announce that Xueying has been selected as a recipient of the 2025 GROWW Scholarship. This competitive program strives to positively impact the lives of all people who identify as women and to inspire individuals who are dedicated to propelling womenâ€™s health.",
    tag: "News",
    url: "",
    image: "/assets/images/news/GROWW.png",
    article: `
    We are proud to announce that Xueying has been selected as a recipient of the 2025 GROWW Scholarship. This competitive program strives to positively impact the lives of all people who identify as women and to inspire individuals who are dedicated to propelling womenâ€™s health. 
    
    The cohort program annually accepts a group of 20 clinical trainees, graduate students, post-doctoral fellows, and ECRs from across Canada chosen through a competitive application process. They will provide Xueying with valuable mentorship, interdisciplinary collaboration opportunities, and research support as she continues developing inclusive and human-centered interaction systems for womenâ€™s health. Congratulations, Xueying, on this exciting achievement! ğŸŒŸ

    The GROWW (Guiding interdisciplinary Research On Womenâ€™s and girlsâ€™ health and Wellbeing) program is a Health Research Training Platform (HRTP) supported by the CIHR Institute of Gender and Health, Indigenous Peopleâ€™s Health and Human Development, Child and Youth Health. Learn more about the program <a href="https://www.growwprogram.com/" class="text-blue-700" > here</a>.
    `
  },

  {
    title: "Two Posters Accepted at GI 2025",
    date: "May, 2025",
    description: "Congratulations to Qihan and Xueying for having their posters accepted to Graphics Interface 2025. We're excited to see you in Kelowna this May!",
    tag: "Conference",
    url: "",
    image: "/assets/images/news/GI2025.png",
    article: `
      Weâ€™re excited to share that two posters from Tangent Lab have been accepted to <a href="https://graphicsinterface.org/conference/2025/" target="_blank" rel="noopener noreferrer">Graphics Interface 2025</a> in Kelowna, British Columbia, Canada ğŸ‡¨ğŸ‡¦!

      ğŸ¦¾ <strong>â€œGuide Me Through that Door!â€œ: Teach Guiding Robot to Go Through a Door with Reinforcement Learning</strong> â€” by Qihan Gao and Lawrence Kim
      ğŸŒ€ <strong>Designing Swarm Robot Interactions for Everyday Anxiety Regulation</strong> â€” by Xueying Zhang and Lawrence Kim

      Congratulations to Qihan and Xueying on these exciting contributions! Weâ€™re proud to showcase our ongoing work in HCI at GIâ€™25. ğŸ‘
    `
  },

  {
  title: "Duc and JangHyeon Presented at CHI 2025",
  date: "April, 2025",
  description: "Duc and JangHyeon presented three papers at CHI 2025 in Yokohama, Japan. You can now watch their talks and read the full papers on our Publications page!",
  tag: "Conference",
  image: "/assets/images/news/CHI25.4.jpg",
  url: "",
  article: `
    Our lab is thrilled to be part of <a href="https://chi2025.acm.org/" target="_blank" rel="noopener noreferrer">CHI 2025</a> held in Yokohama, Japan ğŸ‡¯ğŸ‡µ! This week, Duc and JangHyeon presented three papers accepted:
    
    
    <div class="text-lg font-medium"> ğŸ… Honorable Mention Award: User-Defined Co-Speech Gesture Design with Swarm Robots</div> 
    Minh Duc Dang, Samira Pulatova, and Lawrence Kim

    Non-verbal signals, including co-speech gestures, play a vital role in human communication by conveying nuanced meanings beyond verbal discourse. While researchers have explored co-speech gestures in human-like conversational agents, limited attention has been given to non-humanoid alternatives. In this paper, we propose using swarm robotic systems as conversational agents and introduce a foundational set of swarm-based co-speech gestures, elicited from non-technical users and validated through an online study. This work outlines the key software and hardware requirements to advance research in co-speech gesture generation with swarm robots, contributing to the future development of social robotics and conversational agents.

    <div class="flex place-content-center">
      <img src="/assets/images/news/CHI25.1.jpg" class="rounded-lg" alt="CHI25.1">
    </div>

    <div class="text-lg font-medium"> ğŸª„ DiminishAR: Diminishing Visual Distractions via Holographic AR Displays  </div> 
    JangHyeon Lee and Lawrence Kim
    
    Smartphones are integral to modern life, yet research highlights the cognitive drawbacks associated with their mere presence. While physically removing them can mitigate these effects, it is often inconvenient and may heighten anxiety due to prolonged separation. To address this, we use holographic augmented reality (AR) displays to visually diminish distractions with two interventions: 1) Visual Camouflage, which disguises the smartphone with a hologram that matches its size and blends with the background, making it less noticeable, and 2) Visual Substitution, which occludes the smartphone with a contextually relevant hologram, like books on a desk. In a study with 60 participants, we compared cognitive performance with the smartphone nearby, remote, and visually diminished by our AR interventions. Our findings show that the interventions significantly reduce cognitive impairment, with effects comparable to physically removing the smartphone. The adaptability of our approach opens new avenues to manage visual distractions in daily life.

    <div class="flex place-content-center">
      <img src="/assets/images/news/CHI25.3.jpg" class="rounded-lg" alt="CHI25.3">
    </div>
    
    <div class="text-lg font-medium"> ğŸ†™ Co-Design & Evaluation of Visual Interventions for Head Posture Correction in Virtual Reality Games </div> 
    Minh Duc Dang, Duy Phuoc Luong, Christopher Napier, and Lawrence Kim 

    While virtual reality (VR) games offer immersive experiences, prolonged improper head posture during VR gaming sessions can cause neck discomfort and injuries. To address this issue, we prototyped a framework to detect instances of improper head posture and apply various visual interventions to correct them. After assessing the prototype's usability in a co-design workshop with participants experienced in VR design and kinesiology, we refined the interventions in two main directions --- using explicit visual indicators or employing implicit background changes. The refined interventions were subsequently tested in a controlled experiment involving a target selection task. The study results demonstrate that the interventions effectively helped participants maintain better head posture during VR gameplay compared to the control condition.

    <div class="flex place-content-center">
      <img src="/assets/images/news/CHI25.2.jpg" class="rounded-lg" alt="CHI25.2">
    </div>
    
    Huge congratulations to everyone involved, and thank you Duc and JangHyeon for proudly representing Tangent Lab on CHI! ğŸ‘ğŸ‘ Please learn more about the papers and presentations at <a href="https://tangent.cs.sfu.ca/#publications" class="text-blue-700" > our publication page</a>.
    
    <div class="flex place-content-center">
      <img src="/assets/images/news/CHI25.5.jpg" class="rounded-lg" alt="CHI25.5">
    </div>
  `
  },

  
  {
    title: "Qihan and Sarah Recognized at the 2025 SFU CS Diversity Awards",
    date: "April, 2025",
    description: "Qihan won the 2025 CS Diversity Award for his project on â€œIntelligent Guiding Robot System for Blind and Visually Impaired People Enabling Independent Navigationâ€.",
    url: "",
    image:"/assets/images/news/2025.04-CS Diversity Award 2.png",
    tag:"News",
    article:
    `
    We are proud to share that two projects from Tangent Lab were recognized at the 2025 CS Diversity Awards, celebrating initiatives that advance diversity, inclusion, equity, and justice in computing science.


    
    <div class="text-xl font-medium"> ğŸ¥‡ Joint Winner: Intelligent Guiding Robot System for Blind and Visually Impaired People Enabling Independent Navigation </div> 
    Team Members: Qihan Gao, Shaojun Cai, Kwek Bin Chong
    Advisors: Lawrence Kim, David Hsu

    <div class="flex place-content-center">
        <img src="/assets/images/news/2025.04-CS Diversity Award 4.png"  class="rounded-lg" alt="Diversity Award Qihan">
    </div>
    This project developed an intelligent navigation assistant system for robotic guide platforms, integrating a voice interface, reasoning backbone for planning and decision-making, and modular functions such as object detection, text reading, and environmental description. Deployed on a quadruped robot, the system enables users to navigate complex public environments with greater autonomy. Field tests demonstrate its potential to support blind users in performing everyday tasks more independently. This work exemplifies how advanced AI and robotics can be developed to support inclusive design, ensuring that emerging technologies are accessible and empowering for everyone.


    <div class="text-xl font-medium"> ğŸ‰ Finalist: Facilitating Bids for Conversation Entry using ConvoBuddy, A Chatbot Conversation Assistant  </div>     
    Team Members: Sarah Jade Pratt, Kenny Zhang
    Advisor: Xing-Dong Yang

    <div class="flex place-content-center">
      <img src="/assets/images/news/2025.04-CS Diversity Award 3.png" class="rounded-lg" alt="Diversity Award Sarah">
    </div>
    Facilitating smooth entry into ongoing conversations is essential for fostering inclusive and enjoyable social interactions, yet it remains one of the most challenging aspects of conversational dynamics. This project presents ConvoBuddy, a novel conversational assistant designed to support users actively seeking to join existing conversational groups based upon a preliminary need-finding user study and literature review.


    Congratulations to both teams for their outstanding contributions to promoting inclusivity in computing science!
    ğŸ“ Learn more about the award and other recognized projects here: <a href="https://www.sfu.ca/fas/computing/about/diversity-cs/csdc-diversity-project-presentations/2025-diversity-project-presentations.html" class="text-blue-700" >2025 Diversity Project Presentations â€“ SFU School of Computing Science</a>
    `
  },

  {
    title: "One Best Paper Honorable Mention Award for CHI 2025",
    date: "Mar, 2025",
    description: "Duc and Samira received a Best Paper Honorable Mention award for their CHI 2025 paper: â€œUser-Defined Co-Speech Gesture Design with Swarm Robotsâ€. Congratulations! ",
    url: "",
    image:"/assets/images/publications/SwarmCoSpeechGesture.gif",
    tag:"News",
    article:
    `
    We are pleased to share that Duc and Samira have received a Best Paper Honorable Mention Award at the upcoming ACM CHI Conference on Human Factors in Computing Systems (CHI 2025).

    Their paper, titled â€œUser-Defined Co-Speech Gesture Design with Swarm Robotsâ€, was recognized for its contribution to advancing user-centered design in human-robot interaction.

    Congratulations to the authors on this well-deserved recognition!
    See you at CHI 2025 this April in Japan. ğŸ‡¯ğŸ‡µâœˆï¸
  `
  },

  {
    title: "Timâ€™s MSc Thesis Defense",
    date: "Mar, 2025",
    description: "Congratulations to Tim on successfully defending his MSc thesis! His MSc thesis is titled, â€œTowards Human-Centered, Open, and Social Interfaces for AIâ€.",
    url: "",
    image:"/assets/images/news/IMG_8992 Large.jpeg",
    tag:"News",
    article:
    `
    Big congratulations to Tim for successfully defending his Master's thesis! ğŸ¥³ğŸ‘
    His thesis, titled â€œTowards Human-Centered, Open, and Social Interfaces for AIâ€, explores new directions for more user-friendely and transparent AI interaction. Weâ€™re so proud of this milestoneâ€”well done, Tim! ğŸ‰ğŸ“˜

  `
  },

  {
    title: "Three Papers Conditionally Accepted to CHI 2025",
    date: "Jan, 2025",
    description: "We are thrilled to announce that three of our lab's research papers have been conditionally accepted to CHI 2025. Congratulations to JangHyeon, Duc, Samira, Lawrence and all the authors for their incredible contributions! ",
    url: "",
    image:"/assets/images/news/chi25.png",
    tag:"News",
    article:
    `
    We are thrilled to announce that three of our lab's research papers have been conditionally accepted to CHI 2025:

    1. DiminishAR: Diminishing Visual Distractions via Holographic AR Displays by JangHyeon Lee, Lawrence Kim.
    2. Co-Design & Evaluation of Visual Interventions for Head Posture Correction in Virtual Reality Games by Minh Duc Dang, Duy Phuoc Luong, Christopher Napier, Lawrence Kim.
    3. User-Defined Co-Speech Gesture Design with Swarm Robots by Minh Duc Dang, Samira Pulatova, Lawrence Kim.
    
    Congratulations to all the authors for their incredible contributions!
  `
  },

  /*
  {
    title: "Tangent Lab Holiday Party 2024",
    date: "Dec, 2024",
    description: "Wrapped up the year with a home-cooked feast, chaotic White Elephant trades, and some intense card games ğŸğŸ„ Grateful for the amazing Tangent Lab crewâ€”hereâ€™s to another year of innovation and fun! ğŸ¥‚âœ¨",
    url: "",
    image:"/assets/images/news/IMG_8506.jpg",
    tag:"News",
    article:
    `
    Wrapped up 2024 with a feast, laughter, and festive chaos! ğŸ½ï¸ğŸ 
    After a hearty dinner, the lab dove into a White Elephant gift exchange, filled with surprises, steals, and plenty of holiday spirit. 
    A perfect way to celebrate the end of the year with an amazing team! âœ¨ğŸ¥‚
  `
  },
  */

  {
    title: "Sarah Presented at VINCI Event",
    date: "Dec, 2024",
    description: "Held at SFUâ€™s Harbour Centre, the first public VINCI event opened with remarks from SFUâ€™s Vice-President, Research and International, Dugan Oâ€™Neil, and VINCI co-directors Parmit Chilana and Manolis Savva. ",
    url: "https://www.sfu.ca/fas/computing/news-events/news/2024/12/shaping-the-future-with-ai--vinci-leads-the-way-at-sfu.html",
    image: "/assets/images/news/vinci.png",
    tag:"News",
    article:"Held at SFUâ€™s Harbour Centre, the first public VINCI event opened with remarks from SFUâ€™s Vice-President, Research and International, Dugan Oâ€™Neil, and VINCI co-directors Parmit Chilana and Manolis Savva. ",
  },
  
  {
    title: "Samira Presented at ASSETS 2024",
    date: "Nov, 2024",
    description: "Samira gave a talk about her latest research at ASSETS 2024 conference. Individuals with ADHD grapple with elevated stress levels, emotional regulation challenges, and difficulty sustaining focus. Fidgeting, a behavior traditionally frowned upon, has been shown to help people with ADHD in concentration, emotional and mental state management, and energy regulation. However, traditional fidgeting devices have limited fixed affordances providing cookie-cutter style fidgeting experience to all despite individual differences. Recognizing the uniqueness of individual fidgeting tendencies, we use small tabletop robots to provide a customizable fidgeting interaction experience and conduct co-design sessions with 16 adults diagnosed with ADHD to explore how they envision their fidgeting interactions being changed with these programmable robots. We examine core elements defining a successful fidgeting interaction with robots, assess the significance of customizability in these interactions and any common trends among participants, and investigate additional advantages that interactions with robots may offer. This research reveals nuanced preferences of adults with ADHD concerning robot-assisted fidgeting.",
    url: "https://www.youtube.com/watch?v=vglfyKbNiHE",
    image: "/assets/images/news/ASSETSâ€™24.png",
    tag:"News",
    article:"",
  },
  {
    title: "Tian and Tim Presented at CHI 2024",
    date: "May, 2024",
    description: "Tian and Tim gave a talk about their research at CHI 2024 conference.",
    url: "",
    image: "/assets/images/news/chi24.png",
    tag:"News",
    article:"",
  },

  {
    title: "Tangent Lab Holiday Party!",
    date: "Dec, 2023",
    description: "Wrapped up the year with a home-cooked feast, chaotic White Elephant trades, and some intense card games ğŸğŸ„ Grateful for the amazing Tangent Lab crewâ€”hereâ€™s to another year of innovation and fun! ğŸ¥‚âœ¨",
    url: "",
    image:"/assets/images/news/2023.12-Holiday Large.jpeg",
    tag:"News",
    article:
    `
    Wrapped up the year with a home-cooked feast, chaotic White Elephant trades, and some intense card games ğŸğŸ„
    Grateful for the amazing Tangent Lab crewâ€”hereâ€™s to another year of innovation and fun! ğŸ¥‚âœ¨
  `
  },

  {
    title: "Tangent Lab at UIST 2023",
    date: "Oct, 2023",
    description: "Samira, JangHyeon, Tian, and Lawrence presented a paper and demo on SwarmFidget at UIST 2023.",
    url: "",
    image:"/assets/images/news/UIST23.png",
    tag:"News",
    article:
    `
    Samira, JangHyeon, Tian, and Lawrence presented a paper and demo on SwarmFidget at UIST 2023.

  `
  },

  {
    title: "Tangent Lab @Stanley Park!",
    date: "Jul, 2023",
    description: "Rolling into summer with Tangent Lab! â˜€ï¸ğŸ›¼ğŸš´ A perfect day of biking, rollerblading, and a Gimbap picnic at Stanley Parkâ€”good vibes, great views, and even better company!",
    url: "",
    image:"/assets/images/news/2023.07-Stanley Park Large.jpeg",
    tag:"News",
    article:
    `
    Rolling into summer with Tangent Lab! â˜€ï¸ğŸ›¼ğŸš´ 
    A perfect day of biking, rollerblading, and a Gimbap picnic at Stanley Parkâ€”good vibes, great views, and even better company!
  `
  },
];
  